"""
í•œêµ­ ìœ„í‚¤í”¼ë””ì•„ í¬ë¡¤ë§ ë° íŒŒì‹± ëª¨ë“ˆ
- ìœ„í‚¤ ë¬¸ì„œ í¬ë¡¤ë§ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
- GPT APIë¥¼ ì´ìš©í•œ ìš”ì•½ ìƒì„±
- MCP ì¹œí™”ì  íŒŒì¼ëª… ìƒì„± (í•œê¸€ëª…/ì˜ì–´ëª…/ìš”ì•½)
"""

import requests
from bs4 import BeautifulSoup
import re
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import openai
from openai import OpenAI
import time
import json


class WikiDataParser:
    """ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„° íŒŒì‹± ë° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, openai_api_key: str, output_dir: str = "data/raw/"):
        """
        ì´ˆê¸°í™”
        Args:
            openai_api_key: OpenAI API í‚¤
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.client = OpenAI(api_key=openai_api_key)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ìš”ì²­ í—¤ë” ì„¤ì • (ìœ„í‚¤í”¼ë””ì•„ í¬ë¡¤ë§ ì—í‹°ì¼“)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    def crawl_wikipedia_page(self, url: str) -> Tuple[str, str]:
        """
        ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì œëª©ê³¼ ë³¸ë¬¸ì„ Markdown+LaTeX í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ
        
        Args:
            url: ìœ„í‚¤í”¼ë””ì•„ URL
            
        Returns:
            Tuple[ì œëª©, Markdown í˜•ì‹ì˜ ë³¸ë¬¸í…ìŠ¤íŠ¸]
        """
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì œëª© ì¶”ì¶œ
            title = soup.find('h1', {'class': 'firstHeading'})
            title_text = title.get_text().strip() if title else "ì œëª©ì—†ìŒ"
            
            # ë³¸ë¬¸ ì¶”ì¶œ (mw-parser-output í´ë˜ìŠ¤ ë‚´ì˜ ëª¨ë“  ìš”ì†Œë“¤)
            content_div = soup.find('div', {'class': 'mw-parser-output'})
            if not content_div:
                return title_text, "ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            markdown_content = self._convert_to_markdown(content_div, title_text)
            
            return title_text, markdown_content.strip()
            
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì˜¤ë¥˜ ({url}): {e}")
            return "í¬ë¡¤ë§ ì‹¤íŒ¨", f"ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def _convert_to_markdown(self, content_div, title: str) -> str:
        """
        HTML ë‚´ìš©ì„ Markdown+LaTeX í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            content_div: BeautifulSoup ìš”ì†Œ
            title: ë¬¸ì„œ ì œëª©
            
        Returns:
            Markdown í˜•ì‹ì˜ í…ìŠ¤íŠ¸
        """
        markdown_text = f"# {title}\n\n"
        
        # í…œí”Œë¦¿ê³¼ ë„¤ë¹„ê²Œì´ì…˜ ìš”ì†Œ ì œê±°
        self._remove_template_elements(content_div)
        
        # ì²˜ë¦¬í•  ìš”ì†Œë“¤ì„ ìˆœì„œëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸°
        elements = content_div.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'ul', 'ol', 'div'])
        
        # ì œì™¸í•  ì„¹ì…˜ ê°ì§€ìš© í”Œë˜ê·¸
        skip_content = False
        
        for element in elements:
            # ì œì™¸í•  ì„¹ì…˜ì¸ì§€ í™•ì¸
            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                header_text = self._clean_text(element.get_text()).lower()
                if self._should_skip_section(header_text):
                    skip_content = True
                    print(f"  ğŸ“ ì„¹ì…˜ ì œì™¸: {header_text}")
                    continue
                # ë©”ì¸ ì„¹ì…˜ì´ë©´ ë‹¤ì‹œ í¬í•¨
                elif self._is_main_section(header_text):
                    skip_content = False
            
            # ì œì™¸í•  ì„¹ì…˜ ë‚´ìš©ì´ë©´ ê±´ë„ˆë›°ê¸°
            if skip_content:
                continue
            
            # ìˆ˜ì‹ ì²˜ë¦¬
            self._process_math_elements(element)
            
            # ìš”ì†Œë³„ ì²˜ë¦¬
            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(element.name[1]) + 1  # h1ì€ ì´ë¯¸ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ +1
                if level <= 6:
                    header_text = self._clean_text(element.get_text())
                    markdown_text += f"{'#' * level} {header_text}\n\n"
            
            elif element.name == 'p':
                para_text = self._process_paragraph(element)
                if para_text and len(para_text.strip()) > 10:
                    markdown_text += f"{para_text}\n\n"
            
            elif element.name in ['ul', 'ol']:
                list_text = self._process_list(element)
                if list_text:
                    markdown_text += f"{list_text}\n\n"
            
            elif element.name == 'div' and 'mwe-math-element' in element.get('class', []):
                # ìˆ˜ì‹ ë¸”ë¡ ì²˜ë¦¬
                math_text = self._extract_math_latex(element)
                if math_text:
                    markdown_text += f"$$\n{math_text}\n$$\n\n"
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        markdown_text = re.sub(r'\n{3,}', '\n\n', markdown_text)  # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
        markdown_text = re.sub(r'\[\d+\]', '', markdown_text)     # ê°ì£¼ ë²ˆí˜¸ ì œê±°
        
        return markdown_text
    
    def _remove_template_elements(self, content_div):
        """
        ìœ„í‚¤í”¼ë””ì•„ í…œí”Œë¦¿ê³¼ ë„¤ë¹„ê²Œì´ì…˜ ìš”ì†Œë“¤ì„ ì œê±°
        
        Args:
            content_div: BeautifulSoup ìš”ì†Œ
        """
        # ì œê±°í•  ìš”ì†Œë“¤ì˜ í´ë˜ìŠ¤ì™€ ID ëª©ë¡
        removal_selectors = [
            # ë„¤ë¹„ê²Œì´ì…˜ ë°•ìŠ¤
            '.navbox',
            '.navbox-inner', 
            '.navbox-group',
            '.navigation-box',
            
            # ì‚¬ì´ë“œë°”
            '.sidebar',
            '.infobox',
            '.infobox-above',
            '.infobox-subheader',
            
            # ë©”ì‹œì§€ ë°•ìŠ¤
            '.mbox',
            '.ambox',
            '.tmbox',
            '.cmbox',
            '.ombox',
            '.fmbox',
            '.dmbox',
            
            # ì¹´í…Œê³ ë¦¬ ë°•ìŠ¤
            '.catlinks',
            '.mw-normal-catlinks',
            
            # ê¸°íƒ€ í…œí”Œë¦¿ë“¤
            '.hatnote',
            '.dablink',
            '.rellink',
            '.navframe',
            '.collapsible',
            
            # í¸ì§‘ ê´€ë ¨
            '.mw-editsection',
            '.mw-editsection-bracket',
            
            # ì°¸ì¡° ê´€ë ¨
            '.reference',
            '.reflist',
            '.refbegin',
            '.refend',
            
            # ëª©ì°¨
            '.toc',
            '#toc',
            
            # ê¸°íƒ€
            '.printfooter',
            '.mw-jump-link',
            '.visualhide',
            '.nomobile',
        ]
        
        # CSS ì„ íƒìë¡œ ìš”ì†Œ ì œê±°
        for selector in removal_selectors:
            elements = content_div.select(selector)
            for element in elements:
                element.decompose()
        
        # role ì†ì„±ìœ¼ë¡œ ì œê±°
        navigation_elements = content_div.find_all(attrs={'role': 'navigation'})
        for element in navigation_elements:
            element.decompose()
        
        # í…Œì´ë¸” í˜•íƒœì˜ í…œí”Œë¦¿ ì œê±° (íŠ¹ì • í´ë˜ìŠ¤ê°€ ìˆëŠ” ê²ƒë“¤)
        tables = content_div.find_all('table')
        for table in tables:
            table_classes = table.get('class', [])
            if any(cls in ['navbox', 'infobox', 'sidebar', 'vertical-navbox', 'geography', 'biota'] 
                   for cls in table_classes):
                table.decompose()
                continue
            
            # í…Œì´ë¸”ì´ ë„ˆë¬´ ë§ì€ ë§í¬ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©´ ë„¤ë¹„ê²Œì´ì…˜ ë°•ìŠ¤ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            links = table.find_all('a')
            if len(links) > 20:  # ë§í¬ê°€ 20ê°œ ì´ìƒì´ë©´ ë„¤ë¹„ê²Œì´ì…˜ìœ¼ë¡œ ê°„ì£¼
                table.decompose()
        
        # ë³¸ë¬¸ ì‹œì‘ ì „ ë¦¬ìŠ¤íŠ¸ë“¤ ì œê±° (ì²« ë²ˆì§¸ ë¬¸ë‹¨ ì´ì „ì˜ ë¦¬ìŠ¤íŠ¸ë“¤)
        self._remove_pre_content_lists(content_div)
        
        print(f"  ğŸ§¹ í…œí”Œë¦¿ ìš”ì†Œ ì œê±° ì™„ë£Œ")

    def _remove_pre_content_lists(self, content_div):
        """
        ë³¸ë¬¸ ì‹œì‘ ì „ì˜ ë„¤ë¹„ê²Œì´ì…˜ ë¦¬ìŠ¤íŠ¸ë“¤ì„ ì œê±°
        
        Args:
            content_div: BeautifulSoup ìš”ì†Œ
        """
        # ì²« ë²ˆì§¸ ì‹¤ì œ ë¬¸ë‹¨ì„ ì°¾ê¸°
        first_paragraph = None
        for p in content_div.find_all('p'):
            text = p.get_text().strip()
            if len(text) > 50:  # ì¶©ë¶„íˆ ê¸´ ë¬¸ë‹¨
                first_paragraph = p
                break
        
        if not first_paragraph:
            return
        
        # ì²« ë²ˆì§¸ ë¬¸ë‹¨ ì´ì „ì˜ ëª¨ë“  ë¦¬ìŠ¤íŠ¸ ì œê±°
        current = content_div.find()
        while current and current != first_paragraph:
            next_sibling = current.find_next_sibling()
            
            if current.name in ['ul', 'ol']:
                # ë¦¬ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ë§ì€ í•­ëª©ì„ ê°€ì§€ê³  ìˆìœ¼ë©´ ë„¤ë¹„ê²Œì´ì…˜ìœ¼ë¡œ ê°„ì£¼
                list_items = current.find_all('li')
                if len(list_items) > 5:
                    print(f"    ğŸ—‘ï¸ ì‚¬ì „ ë¦¬ìŠ¤íŠ¸ ì œê±°: {len(list_items)}ê°œ í•­ëª©")
                    current.decompose()
            
            current = next_sibling

    def _is_template_list(self, ul_element) -> bool:
        """
        ë¦¬ìŠ¤íŠ¸ê°€ í…œí”Œë¦¿/ë„¤ë¹„ê²Œì´ì…˜ ìš”ì†Œì¸ì§€ íŒë‹¨
        
        Args:
            ul_element: BeautifulSoup ul ìš”ì†Œ
            
        Returns:
            í…œí”Œë¦¿ ë¦¬ìŠ¤íŠ¸ì´ë©´ True
        """
        # ë¶€ëª¨ ìš”ì†Œë“¤ í™•ì¸
        parent = ul_element.parent
        while parent:
            if parent.get('class'):
                parent_classes = parent.get('class', [])
                if any(cls in ['navbox', 'sidebar', 'infobox', 'navigation'] 
                       for cls in parent_classes):
                    return True
            parent = parent.parent
        
        # ë¦¬ìŠ¤íŠ¸ ë‚´ìš© í™•ì¸
        list_items = ul_element.find_all('li')
        if len(list_items) > 10:  # 10ê°œ ì´ìƒì˜ í•­ëª©
            # ëŒ€ë¶€ë¶„ì´ ë§í¬ì¸ì§€ í™•ì¸
            link_count = len(ul_element.find_all('a'))
            if link_count / len(list_items) > 0.7:  # 70% ì´ìƒì´ ë§í¬
                return True
        
        return False
    
    def _should_skip_section(self, header_text: str) -> bool:
        """
        ì œì™¸í•  ì„¹ì…˜ì¸ì§€ í™•ì¸
        
        Args:
            header_text: ì†Œë¬¸ìë¡œ ë³€í™˜ëœ í—¤ë” í…ìŠ¤íŠ¸
            
        Returns:
            ì œì™¸í•  ì„¹ì…˜ì´ë©´ True
        """
        skip_keywords = [
            # í•œê¸€
            'ê°™ì´ ë³´ê¸°', 'ê°™ì´ë³´ê¸°', 'ê´€ë ¨ í•­ëª©', 'ê´€ë ¨í•­ëª©',
            'ê°ì£¼', 'ì£¼ì„', 'ì°¸ì¡°', 'ì¶œì²˜', 'ì°¸ê³  ë¬¸í—Œ', 'ì°¸ê³ ë¬¸í—Œ',
            'ì™¸ë¶€ ë§í¬', 'ì™¸ë¶€ë§í¬', 'ë°”ê¹¥ ë§í¬', 'ë°”ê¹¥ë§í¬',
            'ë” ë³´ê¸°', 'ë”ë³´ê¸°', 'ì°¸ê³  ìë£Œ', 'ì°¸ê³ ìë£Œ',
            'ì™¸ë¶€ ê³ ë¦¬', 'ë°”ê¹¥ ê³ ë¦¬', 'ì½ì„ê±°ë¦¬', 'ì½ì„ ê±°ë¦¬',
            
            # ì˜ê¸€ (í˜¹ì‹œ ì˜ë¬¸ ìœ„í‚¤ ì²˜ë¦¬í•  ê²½ìš°)
            'see also', 'references', 'external links', 'further reading',
            'notes', 'citations', 'bibliography', 'sources',
            'related articles', 'related topics'
        ]
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨í•˜ëŠ” ê²½ìš°
        for keyword in skip_keywords:
            if keyword in header_text or header_text.strip() == keyword:
                return True
        
        return False
    
    def _is_main_section(self, header_text: str) -> bool:
        """
        ë©”ì¸ ì„¹ì…˜ì¸ì§€ í™•ì¸ (ì œì™¸ ì„¹ì…˜ ì´í›„ì— ë‚˜ì˜¤ëŠ” ì£¼ìš” ì„¹ì…˜)
        
        Args:
            header_text: ì†Œë¬¸ìë¡œ ë³€í™˜ëœ í—¤ë” í…ìŠ¤íŠ¸
            
        Returns:
            ë©”ì¸ ì„¹ì…˜ì´ë©´ True
        """
        main_keywords = [
            'ê°œìš”', 'ì •ì˜', 'ì—­ì‚¬', 'íŠ¹ì§•', 'ì›ë¦¬', 'ë°©ë²•', 'êµ¬ì¡°',
            'ì¢…ë¥˜', 'ë¶„ë¥˜', 'ì‘ìš©', 'í™œìš©', 'ì¥ì ', 'ë‹¨ì ', 'í•œê³„',
            'ì•Œê³ ë¦¬ì¦˜', 'ëª¨ë¸', 'ì´ë¡ ', 'ìˆ˜ì‹', 'ê³µì‹'
        ]
        
        for keyword in main_keywords:
            if keyword in header_text:
                return True
        
        return False
    
    def _process_math_elements(self, element):
        """
        ìš”ì†Œ ë‚´ì˜ ìˆ˜ì‹ë“¤ì„ LaTeX í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            element: BeautifulSoup ìš”ì†Œ
        """
        # ì¸ë¼ì¸ ìˆ˜ì‹ ì²˜ë¦¬
        math_spans = element.find_all('span', class_='mwe-math-element')
        for math_span in math_spans:
            latex_text = self._extract_math_latex(math_span)
            if latex_text:
                # ì¸ë¼ì¸ ìˆ˜ì‹ìœ¼ë¡œ ë³€í™˜
                math_span.replace_with(f"${latex_text}$")
        
        # MathML ì²˜ë¦¬
        math_elements = element.find_all('math')
        for math_elem in math_elements:
            latex_text = self._mathml_to_latex(math_elem)
            if latex_text:
                math_elem.replace_with(f"${latex_text}$")
    
    def _extract_math_latex(self, math_element) -> str:
        """
        ìˆ˜ì‹ ìš”ì†Œì—ì„œ LaTeX ì½”ë“œ ì¶”ì¶œ
        
        Args:
            math_element: BeautifulSoup ìˆ˜ì‹ ìš”ì†Œ
            
        Returns:
            LaTeX ì½”ë“œ ë¬¸ìì—´
        """
        # data-latex ì†ì„±ì—ì„œ ì¶”ì¶œ
        latex = math_element.get('data-latex')
        if latex:
            return latex.strip()
        
        # img íƒœê·¸ì˜ alt ì†ì„±ì—ì„œ ì¶”ì¶œ
        img = math_element.find('img')
        if img and img.get('alt'):
            alt_text = img.get('alt')
            # LaTeX íŒ¨í„´ ì°¾ê¸°
            latex_match = re.search(r'\\[a-zA-Z]+.*', alt_text)
            if latex_match:
                return latex_match.group().strip()
        
        # script íƒœê·¸ì—ì„œ LaTeX ì¶”ì¶œ
        script = math_element.find('script', type='math/tex')
        if script:
            return script.get_text().strip()
        
        # math íƒœê·¸ ë‚´ìš©ì„ ê°„ë‹¨í•œ LaTeXë¡œ ë³€í™˜
        math_tag = math_element.find('math')
        if math_tag:
            return self._mathml_to_latex(math_tag)
        
        return ""
    
    def _mathml_to_latex(self, math_element) -> str:
        """
        MathMLì„ LaTeXë¡œ ë³€í™˜ (êµ¬ì¡°ì  ë³€í™˜ í¬í•¨)
        
        Args:
            math_element: BeautifulSoup math ìš”ì†Œ
            
        Returns:
            LaTeX ì½”ë“œ ë¬¸ìì—´
        """
        try:
            return self._convert_mathml_element(math_element)
        except:
            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ë³€í™˜ìœ¼ë¡œ í´ë°±
            text = math_element.get_text()
            return self._apply_symbol_replacements(text)
    
    def _convert_mathml_element(self, element) -> str:
        """
        MathML ìš”ì†Œë¥¼ ì¬ê·€ì ìœ¼ë¡œ LaTeXë¡œ ë³€í™˜
        
        Args:
            element: BeautifulSoup MathML ìš”ì†Œ
            
        Returns:
            LaTeX ë¬¸ìì—´
        """
        if element.name == 'math':
            # math ë£¨íŠ¸ ìš”ì†Œ
            return ''.join(self._convert_mathml_element(child) for child in element.children if child.name)
        
        elif element.name == 'mrow':
            # ê·¸ë£¹ ìš”ì†Œ
            return ''.join(self._convert_mathml_element(child) for child in element.children if child.name)
        
        elif element.name == 'mi':
            # ë³€ìˆ˜/ì‹ë³„ì
            text = element.get_text().strip()
            return self._apply_symbol_replacements(text)
        
        elif element.name == 'mn':
            # ìˆ«ì
            return element.get_text().strip()
        
        elif element.name == 'mo':
            # ì—°ì‚°ì
            text = element.get_text().strip()
            return self._apply_operator_replacements(text)
        
        elif element.name == 'mfrac':
            # ë¶„ìˆ˜
            children = [child for child in element.children if child.name]
            if len(children) >= 2:
                numerator = self._convert_mathml_element(children[0])
                denominator = self._convert_mathml_element(children[1])
                return f"\\frac{{{numerator}}}{{{denominator}}}"
            return ''
        
        elif element.name == 'msup':
            # ìœ„ì²¨ì (ì§€ìˆ˜)
            children = [child for child in element.children if child.name]
            if len(children) >= 2:
                base = self._convert_mathml_element(children[0])
                exponent = self._convert_mathml_element(children[1])
                return f"{base}^{{{exponent}}}"
            return ''
        
        elif element.name == 'msub':
            # ì•„ë˜ì²¨ì
            children = [child for child in element.children if child.name]
            if len(children) >= 2:
                base = self._convert_mathml_element(children[0])
                subscript = self._convert_mathml_element(children[1])
                return f"{base}_{{{subscript}}}"
            return ''
        
        elif element.name == 'msubsup':
            # ìœ„ì•„ë˜ì²¨ì
            children = [child for child in element.children if child.name]
            if len(children) >= 3:
                base = self._convert_mathml_element(children[0])
                subscript = self._convert_mathml_element(children[1])
                superscript = self._convert_mathml_element(children[2])
                return f"{base}_{{{subscript}}}^{{{superscript}}}"
            return ''
        
        elif element.name == 'msqrt':
            # ì œê³±ê·¼
            content = ''.join(self._convert_mathml_element(child) for child in element.children if child.name)
            return f"\\sqrt{{{content}}}"
        
        elif element.name == 'mroot':
            # nì œê³±ê·¼
            children = [child for child in element.children if child.name]
            if len(children) >= 2:
                radicand = self._convert_mathml_element(children[0])
                index = self._convert_mathml_element(children[1])
                return f"\\sqrt[{index}]{{{radicand}}}"
            return ''
        
        elif element.name == 'munder':
            # ì•„ë˜ ì²¨ë¶€
            children = [child for child in element.children if child.name]
            if len(children) >= 2:
                base = self._convert_mathml_element(children[0])
                under = self._convert_mathml_element(children[1])
                if base in [r'\sum', r'\int', r'\prod']:
                    return f"{base}_{{{under}}}"
                return f"\\underset{{{under}}}{{{base}}}"
            return ''
        
        elif element.name == 'mover':
            # ìœ„ ì²¨ë¶€
            children = [child for child in element.children if child.name]
            if len(children) >= 2:
                base = self._convert_mathml_element(children[0])
                over = self._convert_mathml_element(children[1])
                return f"\\overset{{{over}}}{{{base}}}"
            return ''
        
        else:
            # ê¸°íƒ€ ìš”ì†ŒëŠ” í…ìŠ¤íŠ¸ ë³€í™˜
            text = element.get_text().strip()
            return self._apply_symbol_replacements(text)
    
    def _apply_symbol_replacements(self, text: str) -> str:
        """
        ê·¸ë¦¬ìŠ¤ ë¬¸ì ë° íŠ¹ìˆ˜ ê¸°í˜¸ë¥¼ LaTeXë¡œ ë³€í™˜
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            LaTeX ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        replacements = {
            # ê·¸ë¦¬ìŠ¤ ë¬¸ì (ì†Œë¬¸ì)
            'Î±': r'\alpha', 'Î²': r'\beta', 'Î³': r'\gamma', 'Î´': r'\delta',
            'Îµ': r'\epsilon', 'Î¶': r'\zeta', 'Î·': r'\eta', 'Î¸': r'\theta',
            'Î¹': r'\iota', 'Îº': r'\kappa', 'Î»': r'\lambda', 'Î¼': r'\mu',
            'Î½': r'\nu', 'Î¾': r'\xi', 'Ï€': r'\pi', 'Ï': r'\rho',
            'Ïƒ': r'\sigma', 'Ï„': r'\tau', 'Ï…': r'\upsilon', 'Ï†': r'\phi',
            'Ï‡': r'\chi', 'Ïˆ': r'\psi', 'Ï‰': r'\omega',
            
            # ê·¸ë¦¬ìŠ¤ ë¬¸ì (ëŒ€ë¬¸ì)
            'Î‘': r'A', 'Î’': r'B', 'Î“': r'\Gamma', 'Î”': r'\Delta',
            'Î•': r'E', 'Î–': r'Z', 'Î—': r'H', 'Î˜': r'\Theta',
            'Î™': r'I', 'Îš': r'K', 'Î›': r'\Lambda', 'Îœ': r'M',
            'Î': r'N', 'Î': r'\Xi', 'Î ': r'\Pi', 'Î¡': r'P',
            'Î£': r'\Sigma', 'Î¤': r'T', 'Î¥': r'\Upsilon', 'Î¦': r'\Phi',
            'Î§': r'X', 'Î¨': r'\Psi', 'Î©': r'\Omega',
            
            # íŠ¹ìˆ˜ ê¸°í˜¸
            'âˆ': r'\infty', 'âˆ‚': r'\partial', 'âˆ‡': r'\nabla',
            'âˆ…': r'\emptyset', 'âˆˆ': r'\in', 'âˆ‰': r'\notin',
            'âˆª': r'\cup', 'âˆ©': r'\cap', 'âŠ‚': r'\subset', 'âŠƒ': r'\supset',
            'âŠ†': r'\subseteq', 'âŠ‡': r'\supseteq', 'â‰¡': r'\equiv',
            'â‰ˆ': r'\approx', 'â‰ ': r'\neq', 'â‰¤': r'\leq', 'â‰¥': r'\geq',
            'Â±': r'\pm', 'âˆ“': r'\mp', 'Ã—': r'\times', 'Ã·': r'\div',
            'Â·': r'\cdot', 'â†’': r'\rightarrow', 'â†': r'\leftarrow',
            'â†”': r'\leftrightarrow', 'â‡’': r'\Rightarrow', 'â‡': r'\Leftarrow',
            'â‡”': r'\Leftrightarrow', 'âˆ€': r'\forall', 'âˆƒ': r'\exists',
            'âˆš': r'\sqrt', 'âˆ‘': r'\sum', 'âˆ': r'\prod', 'âˆ«': r'\int'
        }
        
        for symbol, latex in replacements.items():
            text = text.replace(symbol, latex)
        
        return text
    
    def _apply_operator_replacements(self, text: str) -> str:
        """
        ì—°ì‚°ìë¥¼ LaTeXë¡œ ë³€í™˜
        
        Args:
            text: ì—°ì‚°ì í…ìŠ¤íŠ¸
            
        Returns:
            LaTeX ì—°ì‚°ì
        """
        operator_map = {
            '=': '=',
            '+': '+', 
            '-': '-',
            'Â±': r'\pm',
            'âˆ“': r'\mp',
            'Ã—': r'\times',
            'Â·': r'\cdot',
            'Ã·': r'\div',
            '/': '/',
            'â‰¤': r'\leq',
            'â‰¥': r'\geq',
            '<': '<',
            '>': '>',
            'â‰ ': r'\neq',
            'â‰ˆ': r'\approx',
            'â‰¡': r'\equiv',
            'âˆ': r'\propto',
            'âˆ¼': r'\sim',
            'â†’': r'\rightarrow',
            'â†': r'\leftarrow',
            'â†”': r'\leftrightarrow',
            'âˆˆ': r'\in',
            'âˆ‰': r'\notin',
            'âŠ‚': r'\subset',
            'âŠƒ': r'\supset',
            'âˆª': r'\cup',
            'âˆ©': r'\cap',
            'âˆ§': r'\land',
            'âˆ¨': r'\lor',
            'Â¬': r'\neg',
            'âˆ€': r'\forall',
            'âˆƒ': r'\exists'
        }
        
        return operator_map.get(text.strip(), text)
    
    def _process_paragraph(self, paragraph) -> str:
        """
        ë¬¸ë‹¨ì„ Markdown í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            paragraph: BeautifulSoup p ìš”ì†Œ
            
        Returns:
            Markdown í˜•ì‹ì˜ ë¬¸ë‹¨ í…ìŠ¤íŠ¸
        """
        # ê°ì£¼ ë° ì°¸ì¡° ê´€ë ¨ ìš”ì†Œ ì œê±°
        for sup in paragraph.find_all('sup'):
            sup.decompose()
        
        # ì°¸ì¡° ê´€ë ¨ span ì œê±° (classê°€ referenceì¸ ê²ƒë“¤)
        for ref_span in paragraph.find_all('span', class_=['reference', 'mw-ref']):
            ref_span.decompose()
        
        # í¸ì§‘ ë§í¬ ì œê±° ([í¸ì§‘] ë“±)
        for edit_span in paragraph.find_all('span', class_='mw-editsection'):
            edit_span.decompose()
        
        # ë§í¬ ì²˜ë¦¬ - ëª¨ë“  ë§í¬ë¥¼ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¸°ê³  URL ì œê±°
        for link in paragraph.find_all('a'):
            link_text = link.get_text().strip()
            
            # íŠ¹ìˆ˜ ë§í¬ë“¤ì€ ì™„ì „íˆ ì œê±°
            if (link.get('href', '').startswith('#cite') or 
                link.get('href', '').startswith('#ref') or 
                link.get('href', '').startswith('#note') or
                'cite_note' in link.get('href', '') or
                'cite_ref' in link.get('href', '') or
                '[í¸ì§‘]' in link_text or 
                'edit' in link_text.lower() or
                link.get('class') and any('reference' in str(cls) for cls in link.get('class', []))):
                link.decompose()
                continue
            
            # ëª¨ë“  ì¼ë°˜ ë§í¬ëŠ” í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¸°ê¸°
            if link_text:
                link.replace_with(link_text)
            else:
                link.decompose()
        
        # ê°•ì¡° ì²˜ë¦¬
        for strong in paragraph.find_all(['strong', 'b']):
            text = strong.get_text()
            strong.replace_with(f"**{text}**")
        
        for em in paragraph.find_all(['em', 'i']):
            text = em.get_text()
            em.replace_with(f"*{text}*")
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê°ì£¼ ë²ˆí˜¸ íŒ¨í„´ ì œê±°
        text = self._clean_text(paragraph.get_text())
        
        # ê°ì£¼ ë²ˆí˜¸ íŒ¨í„´ ì œê±° (ë” ì •êµí•˜ê²Œ)
        text = re.sub(r'\[\d+\]', '', text)  # [1], [2] ë“±
        text = re.sub(r'\[\d+,\s*\d+\]', '', text)  # [1, 2] ë“±
        text = re.sub(r'\[\d+-\d+\]', '', text)  # [1-3] ë“±
        text = re.sub(r'^\s*\^', '', text)  # ì¤„ ì‹œì‘ì˜ ^ ì œê±°
        
        return text
    
    def _process_list(self, list_element) -> str:
        """
        ë¦¬ìŠ¤íŠ¸ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            list_element: BeautifulSoup ul/ol ìš”ì†Œ
            
        Returns:
            Markdown í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        """
        list_text = ""
        is_ordered = list_element.name == 'ol'
        
        for i, li in enumerate(list_element.find_all('li', recursive=False), 1):
            item_text = self._clean_text(li.get_text())
            if item_text:
                if is_ordered:
                    list_text += f"{i}. {item_text}\n"
                else:
                    list_text += f"- {item_text}\n"
        
        return list_text
    
    def _clean_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì •ë¦¬
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            ì •ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        return text
    
    def summarize_with_gpt(self, text: str, max_length: int = 100) -> str:
        """
        GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìš”ì•½
        
        Args:
            text: ìš”ì•½í•  í…ìŠ¤íŠ¸
            max_length: ìµœëŒ€ ìš”ì•½ ê¸¸ì´
            
        Returns:
            ìš”ì•½ëœ í…ìŠ¤íŠ¸
        """
        try:
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (GPT í† í° ì œí•œ ê³ ë ¤)
            if len(text) > 8000:
                text = text[:8000] + "..."
            
            prompt = f"""
ë‹¤ìŒ ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œë¥¼ {max_length}ì ì´ë‚´ë¡œ í•µì‹¬ ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.
ì „ë¬¸ìš©ì–´ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , MCP ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{text}

ìš”ì•½:
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸°ìˆ  ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            
            # ìš”ì•½ ê¸¸ì´ ì²´í¬ ë° ì¡°ì •
            if len(summary) > max_length:
                summary = summary[:max_length-3] + "..."
            
            return summary
            
        except Exception as e:
            print(f"GPT ìš”ì•½ ì˜¤ë¥˜: {e}")
            return "AI/ML ê´€ë ¨ ê¸°ìˆ  ë¬¸ì„œ"
    
    def get_english_name(self, korean_name: str) -> str:
        """
        í•œê¸€ í‚¤ì›Œë“œì— ëŒ€ì‘í•˜ëŠ” ì˜ì–´ëª… ë°˜í™˜
        
        Args:
            korean_name: í•œê¸€ í‚¤ì›Œë“œ
            
        Returns:
            ì˜ì–´ëª…
        """
        # í•œê¸€-ì˜ì–´ ë§¤í•‘ ì‚¬ì „
        name_mapping = {
            "ì¸ê³µì§€ëŠ¥": "Artificial Intelligence",
            "ê¸°ê³„ í•™ìŠµ": "Machine Learning", 
            "ë”¥ ëŸ¬ë‹": "Deep Learning",
            "í•©ì„±ê³± ì‹ ê²½ë§": "CNN",
            "ìˆœí™˜ ì‹ ê²½ë§": "RNN", 
            "ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬": "LSTM",
            "ê²Œì´íŠ¸ ìˆœí™˜ ìœ ë‹›": "GRU",
            "íŠ¸ëœìŠ¤í¬ë¨¸ (ê¸°ê³„ í•™ìŠµ)": "Transformer",
            "GPT (ì–¸ì–´ ëª¨ë¸)": "GPT",
            "ì•ŒíŒŒê³ ": "AlphaGo",
            "ê°•í™” í•™ìŠµ": "Reinforcement Learning"
        }
        
        return name_mapping.get(korean_name, korean_name)
    
    def create_filename(self, korean_name: str, english_name: str, summary: str) -> str:
        """
        MCP ì¹œí™”ì  íŒŒì¼ëª… ìƒì„±
        
        Args:
            korean_name: í•œê¸€ëª…
            english_name: ì˜ì–´ëª…  
            summary: ìš”ì•½
            
        Returns:
            íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        """
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        def clean_name(name):
            return re.sub(r'[<>:"/\\|?*]', '', name).strip()
        
        korean_clean = clean_name(korean_name)
        english_clean = clean_name(english_name)
        summary_clean = clean_name(summary)
        
        # íŒŒì¼ëª… ì¡°í•©: "í•œê¸€ëª…/ì˜ì–´ëª…/ìš”ì•½"
        filename = f"{korean_clean}/{english_clean}/{summary_clean}"
        
        # íŒŒì¼ëª… ê¸¸ì´ ì œí•œ (255ì)
        if len(filename) > 200:
            filename = filename[:200] + "..."
            
        return filename
    
    def save_document(self, title: str, content: str) -> str:
        """
        Markdown í˜•ì‹ì˜ ë¬¸ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            title: ë¬¸ì„œ ì œëª© (íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©ë¨)
            content: Markdown í˜•ì‹ì˜ ë¬¸ì„œ ë‚´ìš©
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        clean_title = re.sub(r'[<>:"/\\|?*]', '', title).strip()
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„± (.md í™•ì¥ì ì‚¬ìš©)
        file_path = self.output_dir / f"{clean_title}.md"
        
        # Markdown ë©”íƒ€ë°ì´í„° ì¶”ê°€
        full_content = f"""---
title: {title}
type: ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ
format: markdown
---

{content}"""
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        return str(file_path)
    
    def copy_to_mcp_docs(self, results: Dict[str, str], mcp_dir: str = "data/mcp_docs") -> Dict[str, str]:
        """
        ì²˜ë¦¬ëœ Markdown ë¬¸ì„œë“¤ì„ MCPìš©ìœ¼ë¡œ ë³µì‚¬ (ê°„ë‹¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ)
        
        Args:
            results: process_wiki_documentsì˜ ê²°ê³¼ (.md íŒŒì¼ë“¤)
            mcp_dir: MCP ë¬¸ì„œ ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            {í‚¤ì›Œë“œ: MCP_íŒŒì¼_ê²½ë¡œ} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        mcp_path = Path(mcp_dir)
        mcp_path.mkdir(parents=True, exist_ok=True)
        
        mcp_results = {}
        
        print(f"\nğŸ“‹ MCPìš© Markdown íŒŒì¼ ë³µì‚¬ ì¤‘...")
        
        for keyword, original_path in results.items():
            try:
                # ì›ë³¸ Markdown íŒŒì¼ ì½ê¸°
                with open(original_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # MCPìš© ê°„ë‹¨í•œ íŒŒì¼ëª… ìƒì„± (.md í™•ì¥ì ìœ ì§€)
                simple_filename = f"{keyword}.md"
                mcp_file_path = mcp_path / simple_filename
                
                # MCPìš© Markdown íŒŒì¼ ì €ì¥
                with open(mcp_file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                mcp_results[keyword] = str(mcp_file_path)
                print(f"  âœ… {keyword} â†’ {simple_filename}")
                
            except Exception as e:
                print(f"  âŒ {keyword} ë³µì‚¬ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"ğŸ“ MCP Markdown íŒŒì¼ ì €ì¥ ì™„ë£Œ: {mcp_path}")
        return mcp_results

    def process_wiki_documents(self, wiki_data: Dict[str, str]) -> Dict[str, str]:
        """
        ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œë“¤ì„ ì¼ê´„ ì²˜ë¦¬
        
        Args:
            wiki_data: {í‚¤ì›Œë“œ: URL} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            {í‚¤ì›Œë“œ: ì €ì¥ëœ_íŒŒì¼_ê²½ë¡œ} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        print(f"ì´ {len(wiki_data)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...")
        
        for i, (keyword, url) in enumerate(wiki_data.items(), 1):
            print(f"\n[{i}/{len(wiki_data)}] ì²˜ë¦¬ ì¤‘: {keyword}")
            
            try:
                # 1. ìœ„í‚¤í”¼ë””ì•„ í¬ë¡¤ë§
                print("  - í¬ë¡¤ë§ ì¤‘...")
                title, content = self.crawl_wikipedia_page(url)
                
                if content == "ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.":
                    print(f"  - ê±´ë„ˆëœ€: ë‚´ìš© ì—†ìŒ")
                    continue
                
                # 2. íŒŒì¼ ì €ì¥
                print("  - íŒŒì¼ ì €ì¥ ì¤‘...")
                file_path = self.save_document(title, content)
                
                results[keyword] = file_path
                print(f"  - ì™„ë£Œ: {file_path}")
                
                # API ìš”ì²­ ì œí•œ ê³ ë ¤ (1ì´ˆ ëŒ€ê¸°)
                time.sleep(1)
                
            except Exception as e:
                print(f"  - ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        print(f"\nì²˜ë¦¬ ì™„ë£Œ! ì´ {len(results)}ê°œ íŒŒì¼ ìƒì„±ë¨")
        
        # MCPìš© íŒŒì¼ ë³µì‚¬
        if results:
            mcp_results = self.copy_to_mcp_docs(results)
            return results
        
        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„°
    wiki_data = {
        "ì¸ê³µì§€ëŠ¥": "https://ko.wikipedia.org/wiki/ì¸ê³µì§€ëŠ¥",
        "ë¨¸ì‹ ëŸ¬ë‹": "https://ko.wikipedia.org/wiki/ê¸°ê³„_í•™ìŠµ", 
        "ë”¥ëŸ¬ë‹": "https://ko.wikipedia.org/wiki/ë”¥_ëŸ¬ë‹",
        "cnn": "https://ko.wikipedia.org/wiki/í•©ì„±ê³±_ì‹ ê²½ë§",
        "rnn": "https://ko.wikipedia.org/wiki/ìˆœí™˜_ì‹ ê²½ë§",
        "lstm": "https://ko.wikipedia.org/wiki/ì¥ë‹¨ê¸°_ë©”ëª¨ë¦¬",
        "gru": "https://ko.wikipedia.org/wiki/ê²Œì´íŠ¸_ìˆœí™˜_ìœ ë‹›", 
        "transformer": "https://ko.wikipedia.org/wiki/íŠ¸ëœìŠ¤í¬ë¨¸_(ê¸°ê³„_í•™ìŠµ)",
        "gpt": "https://ko.wikipedia.org/wiki/GPT_(ì–¸ì–´_ëª¨ë¸)",
        "alphago": "https://ko.wikipedia.org/wiki/ì•ŒíŒŒê³ ",
        "ê°•í™”í•™ìŠµ": "https://ko.wikipedia.org/wiki/ê°•í™”_í•™ìŠµ"
    }
    
    # OpenAI API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # íŒŒì„œ ì´ˆê¸°í™” ë° ì‹¤í–‰
    parser = WikiDataParser(api_key)
    results = parser.process_wiki_documents(wiki_data)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n=== ì²˜ë¦¬ ê²°ê³¼ ===")
    for keyword, file_path in results.items():
        print(f"{keyword}: {file_path}")


if __name__ == "__main__":
    main() 