"""
ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
1. í¬ë¡¤ë§í•œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ raw í´ë”ì— ì €ì¥
2. MCPìš© ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ëœ íŒŒì¼ì„ mcp_docsì— ì €ì¥  
3. RAGìš© ì „ì²˜ë¦¬ëœ íŒŒì¼ì„ rag_docsì— ì €ì¥
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from utils.data_parser import WikiDataParser
from utils.markdown_processor import MarkdownProcessor
from utils.text_processor import TextProcessor


def main():
    """ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ë©”ì¸ ì‹¤í–‰"""
    
    print("=== ìœ„í‚¤í”¼ë””ì•„ AI/ML ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ===")
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
        print("export OPENAI_API_KEY='your-api-key-here'")
        return
    
    # ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ URL ëª©ë¡
    wiki_data = {
        "ì¸ê³µì§€ëŠ¥": "https://ko.wikipedia.org/wiki/ì¸ê³µì§€ëŠ¥",
        "ë¨¸ì‹ ëŸ¬ë‹": "https://ko.wikipedia.org/wiki/ê¸°ê³„_í•™ìŠµ", 
        "ë”¥ëŸ¬ë‹": "https://ko.wikipedia.org/wiki/ë”¥_ëŸ¬ë‹",
        "cnn": "https://ko.wikipedia.org/wiki/í•©ì„±ê³±_ì‹ ê²½ë§",
        "rnn": "https://ko.wikipedia.org/wiki/ìˆœí™˜_ì‹ ê²½ë§",
        "lstm": "https://ko.wikipedia.org/wiki/ì¥ë‹¨ê¸°_ë©”ëª¨ë¦¬",
        "gru": "https://ko.wikipedia.org/wiki/ê²Œì´íŠ¸_ìˆœí™˜_ìœ ë‹›", 
        "transformer": "https://ko.wikipedia.org/wiki/íŠ¸ëœìŠ¤í¬ë¨¸_(ê¸°ê³„_í•™ìŠµ)",
        "gpt": "https://ko.wikipedia.org/wiki/GPT_(ì–¸ì–´_ëª¨ë¸)",
        "alphago": "https://ko.wikipedia.org/wiki/ì•ŒíŒŒê³ ",
        "ê°•í™”í•™ìŠµ": "https://ko.wikipedia.org/wiki/ê°•í™”_í•™ìŠµ"
    }
    
    try:
        # 1ë‹¨ê³„: ì›ë³¸ í…ìŠ¤íŠ¸ í¬ë¡¤ë§ ë° ì €ì¥
        print("\nğŸ“¥ 1ë‹¨ê³„: ì›ë³¸ í…ìŠ¤íŠ¸ í¬ë¡¤ë§ ë° ì €ì¥")
        raw_dir = project_root / "data" / "raw"
        raw_dir.mkdir(parents=True, exist_ok=True)
        
        raw_results = {}
        for i, (keyword, url) in enumerate(wiki_data.items(), 1):
            print(f"\n[{i}/{len(wiki_data)}] í¬ë¡¤ë§ ì¤‘: {keyword}")
            
            try:
                # ìœ„í‚¤í”¼ë””ì•„ í¬ë¡¤ë§
                parser = WikiDataParser(api_key, str(raw_dir))
                title, content = parser.crawl_wikipedia_page(url)
                
                if content == "ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.":
                    print(f"  - ê±´ë„ˆëœ€: ë‚´ìš© ì—†ìŒ")
                    continue
                
                # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ .txt íŒŒì¼ë¡œ ì €ì¥
                raw_file_path = raw_dir / f"{keyword}.txt"
                with open(raw_file_path, 'w', encoding='utf-8') as f:
                    f.write(f"ì œëª©: {title}\n\n")
                    f.write(content)
                
                raw_results[keyword] = str(raw_file_path)
                print(f"  - ì™„ë£Œ: {raw_file_path}")
                
            except Exception as e:
                print(f"  - ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        print(f"\nâœ… ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {len(raw_results)}ê°œ íŒŒì¼")
        
        # 2ë‹¨ê³„: MCPìš© ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬
        print("\nğŸ“ 2ë‹¨ê³„: MCPìš© ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬")
        mcp_dir = project_root / "data" / "mcp_docs"
        mcp_dir.mkdir(parents=True, exist_ok=True)
        
        markdown_processor = MarkdownProcessor()
        mcp_results = {}
        
        for keyword, raw_path in raw_results.items():
            try:
                print(f"  - ì²˜ë¦¬ ì¤‘: {keyword}")
                
                # ì›ë³¸ í…ìŠ¤íŠ¸ ì½ê¸°
                with open(raw_path, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
                
                # ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬
                markdown_content = markdown_processor.process_for_mcp(raw_content)
                
                # MCPìš© ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
                mcp_file_path = mcp_dir / f"{keyword}.md"
                with open(mcp_file_path, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)
                
                mcp_results[keyword] = str(mcp_file_path)
                print(f"    - ì™„ë£Œ: {mcp_file_path}")
                
            except Exception as e:
                print(f"    - ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        print(f"âœ… MCPìš© ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ì™„ë£Œ: {len(mcp_results)}ê°œ íŒŒì¼")
        
        # 3ë‹¨ê³„: RAGìš© ì „ì²˜ë¦¬
        print("\nğŸ”§ 3ë‹¨ê³„: RAGìš© ì „ì²˜ë¦¬")
        rag_dir = project_root / "data" / "rag_docs"
        rag_dir.mkdir(parents=True, exist_ok=True)
        
        text_processor = TextProcessor()
        rag_results = {}
        
        for keyword, raw_path in raw_results.items():
            try:
                print(f"  - ì²˜ë¦¬ ì¤‘: {keyword}")
                
                # ì›ë³¸ í…ìŠ¤íŠ¸ ì½ê¸°
                with open(raw_path, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
                
                # RAGìš© ì „ì²˜ë¦¬
                processed_content = text_processor.process_for_rag(raw_content)
                
                # RAGìš© í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
                rag_file_path = rag_dir / f"{keyword}.txt"
                with open(rag_file_path, 'w', encoding='utf-8') as f:
                    f.write(processed_content)
                
                rag_results[keyword] = str(rag_file_path)
                print(f"    - ì™„ë£Œ: {rag_file_path}")
                
            except Exception as e:
                print(f"    - ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        print(f"âœ… RAGìš© ì „ì²˜ë¦¬ ì™„ë£Œ: {len(rag_results)}ê°œ íŒŒì¼")
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "="*60)
        print("ğŸ“‹ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"âœ… ì›ë³¸ í…ìŠ¤íŠ¸: {len(raw_results)}ê°œ íŒŒì¼ (data/raw/)")
        print(f"âœ… MCPìš© ë§ˆí¬ë‹¤ìš´: {len(mcp_results)}ê°œ íŒŒì¼ (data/mcp_docs/)")
        print(f"âœ… RAGìš© ì „ì²˜ë¦¬: {len(rag_results)}ê°œ íŒŒì¼ (data/rag_docs/)")
        
        print("\nğŸ“„ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:")
        for keyword in raw_results.keys():
            print(f"  â€¢ {keyword}:")
            print(f"    - ì›ë³¸: data/raw/{keyword}.txt")
            print(f"    - MCP: data/mcp_docs/{keyword}.md")
            print(f"    - RAG: data/rag_docs/{keyword}.txt")
            
        print("\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        print("\n" + "="*60)
        print("ğŸ“– ë‹¤ìŒ ë‹¨ê³„")
        print("="*60)
        print("1. RAG ì‹œìŠ¤í…œ êµ¬ì¶•:")
        print("   uv run rag/build_vectordb.py")
        print()
        print("2. RAG ì±„íŒ… ë°ëª¨:")
        print("   uv run rag/chat_demo.py")
        print()
        print("3. MCP ì„œë²„ ì‹¤í–‰:")
        print("   cd mcp-server")
        print("   uv run mcp_rag_server.py")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ë¬¸ì œê°€ ì§€ì†ë˜ë©´ API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main() 