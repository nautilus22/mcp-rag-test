---
title: 장단기 메모리
type: 위키피디아 문서
format: markdown
---

# 장단기 메모리

- 지도 학습
- 비지도 학습
- 온라인 기계 학습
- 메타-학습
- 준지도 학습
- 자기 지도 학습
- 강화 학습
- 규칙 기반 기계 학습
- 뉴로모픽 엔지니어링
- 양자 기계 학습

- 분류
- 생성 모델
- 회귀 분석
- 클러스터 분석
- 차원 축
- 이상 탐지
- 데이터 정제
- AutoML
- 연관 규칙 학습
- 구조 기반 예측
- 특징 공학
- 특징 학습
- 순위 학습
- 문법 유도
- 온톨로지 학습
- 멀티모달 학습

- 결정 트리 학습법
- 앙상블 학습법 배깅 부스팅 랜덤 포레스트
- 최근접 이웃 탐색
- k-NN
- 선형 회귀
- 나이브 베이즈
- 인공신경망
- 로지스틱 회귀
- 퍼셉트론
- 상관 벡터 머신(RVM)
- 서포트 벡터 머신(SVM)

- 배깅
- 부스팅
- 랜덤 포레스트

- BIRCH
- CURE 알고리즘
- 계층적 군집화
- k-평균 알고리즘
- 퍼지 클러스터링
- 기댓값 최대화 알고리즘
- DBSCAN
- OPTICS
- 평균이동

- 인자 분석
- CCA
- 독립 성분 분석
- 선형 판별 분석
- 음수 미포함 행렬 분해
- 주성분 분석
- t-SNE

- 그래프 모형 베이즈 네트워크 조건부 무작위장 은닉 마르코프 모형
- 잠재 디리클레 할당

- 베이즈 네트워크
- 조건부 무작위장
- 은닉 마르코프 모형

- 무작위 표본 합의
- k-최근접 이웃 알고리즘
- 국소 특이점 요인
- 고립 포레스트

- 오토인코더
- 딥 러닝
- 순방향 신경망
- 순환 신경망 LSTM GRU
- 볼츠만 머신 제한된
- 생성적 적대 신경망
- 확산 모델
- 자기조직화 지도
- 합성곱 신경망 U-Net LeNet 알렉스넷 딥드림
- 신경장 신경 방사장 물리정보 신경망
- 트랜스포머 비전
- 맘바
- 스파이킹 신경망
- 멤트렌지스터
- 전기화학 RAM
- 다층 퍼셉트론

- LSTM
- GRU

- 제한된

- U-Net
- LeNet
- 알렉스넷
- 딥드림

- 신경 방사장
- 물리정보 신경망

- 비전

- Q 러닝
- SARSA
- 시간차 학습

- 액티브 러닝
- 크라우드소싱
- 휴먼인더루프
- RLHF

- 결정계수
- 혼동 행렬
- 러닝 커브
- 수신자 조작 특성

- 커널 메소드
- 편향-분산 트레이드오프
- 계산학습이론
- 경험적 위험 최소화
- PAC 러닝
- 통계적 학습이론
- VC 이론

- NeurIPS
- ICML
- ICLR
- ML
- JMLR

- 기계 학습 알고리즘 목록
- 기계 탈학습
- 지식 증류
- 유사도 학습
- 대조 학습

- v
- t
- e

**장단기 메모리**(Long Short-Term Memory, LSTM)는 [순환 신경망](https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D)(RNN) 기법의 하나로 셀, 입력 게이트, 출력 게이트, 망각 게이트를 이용해 기존 [순환 신경망](https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D)(RNN)의 문제인 [기울기 소멸 문제](https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%9A%B8%EA%B8%B0_%EC%86%8C%EB%A9%B8_%EB%AC%B8%EC%A0%9C)(vanishing gradient problem)를 방지하도록 개발되었다.

LSTM 네트워크는 기존 RNN에 존재하는 [기울기 소멸 문제](https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%9A%B8%EA%B8%B0_%EC%86%8C%EB%A9%B8_%EB%AC%B8%EC%A0%9C)를 처리하는 것을 목표로 한다. 간격 길이에 대한 상대적 둔감성은 다른 RNN, [은닉 마르코프 모형](https://ko.wikipedia.org/wiki/%EC%9D%80%EB%8B%89_%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84_%EB%AA%A8%ED%98%95) 및 기타 시퀀스 학습 방법에 비해 장점이다. 이는 수천 단계 동안 지속될 수 있는 RNN용 단기 메모리, 즉 "장단기 메모리"를 제공하는 것을 목표로 한다. 필기, 음성 인식, 기계 번역, 음성 활동 감지, 로봇 제어, 비디오 게임, 의료 등 시계열 기반 데이터 분류, 처리 및 예측에 적용 가능하다.

일반적인 LSTM 유닛은 셀, 입력 게이트, 출력 게이트 및 망각 게이트로 구성된다. 세포는 임의의 시간 간격에 걸쳐 값을 기억하고 세 개의 게이트는 세포 안팎으로 정보의 흐름을 조절한다. 망각 게이트는 현재 입력과 비교하여 이전 상태에 0과 1 사이의 값을 할당하여 이전 상태에서 삭제할 정보를 결정한다. (반올림) 값 1은 정보를 유지한다는 의미이고, 값 0은 폐기를 의미한다. 입력 게이트는 망각 게이트와 동일한 시스템을 사용하여 현재 상태에 저장할 새로운 정보 조각을 결정한다. 출력 게이트는 이전 상태와 현재 상태를 고려하여 정보에 0부터 1까지의 값을 할당하여 현재 상태의 정보를 출력할 제어한다. 현재 상태에서 관련 정보를 선택적으로 출력하면 LSTM 네트워크가 유용하고 장기적인 종속성을 유지하여 현재와 미래의 시간 단계 모두에서 예측을 할 수 있다.

### 응용

- 시계열
- 음성 인식
- 필기 인식
- 수화
- 이상 탐지
- 비즈니스 성과 관리