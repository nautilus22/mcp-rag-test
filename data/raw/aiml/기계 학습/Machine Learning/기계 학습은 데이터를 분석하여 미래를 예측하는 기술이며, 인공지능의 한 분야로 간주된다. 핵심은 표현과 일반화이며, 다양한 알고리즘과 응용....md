---
title: 기계 학습
type: 위키피디아 문서
format: markdown
---

# 기계 학습

- 지도 학습
- 비지도 학습
- 온라인 기계 학습
- 메타-학습
- 준지도 학습
- 자기 지도 학습
- 강화 학습
- 규칙 기반 기계 학습
- 뉴로모픽 엔지니어링
- 양자 기계 학습

- 분류
- 생성 모델
- 회귀 분석
- 클러스터 분석
- 차원 축
- 이상 탐지
- 데이터 정제
- AutoML
- 연관 규칙 학습
- 구조 기반 예측
- 특징 공학
- 특징 학습
- 순위 학습
- 문법 유도
- 온톨로지 학습
- 멀티모달 학습

- 결정 트리 학습법
- 앙상블 학습법 배깅 부스팅 랜덤 포레스트
- 최근접 이웃 탐색
- k-NN
- 선형 회귀
- 나이브 베이즈
- 인공신경망
- 로지스틱 회귀
- 퍼셉트론
- 상관 벡터 머신(RVM)
- 서포트 벡터 머신(SVM)

- 배깅
- 부스팅
- 랜덤 포레스트

- BIRCH
- CURE 알고리즘
- 계층적 군집화
- k-평균 알고리즘
- 퍼지 클러스터링
- 기댓값 최대화 알고리즘
- DBSCAN
- OPTICS
- 평균이동

- 인자 분석
- CCA
- 독립 성분 분석
- 선형 판별 분석
- 음수 미포함 행렬 분해
- 주성분 분석
- t-SNE

- 그래프 모형 베이즈 네트워크 조건부 무작위장 은닉 마르코프 모형
- 잠재 디리클레 할당

- 베이즈 네트워크
- 조건부 무작위장
- 은닉 마르코프 모형

- 무작위 표본 합의
- k-최근접 이웃 알고리즘
- 국소 특이점 요인
- 고립 포레스트

- 오토인코더
- 딥 러닝
- 순방향 신경망
- 순환 신경망 LSTM GRU
- 볼츠만 머신 제한된
- 생성적 적대 신경망
- 확산 모델
- 자기조직화 지도
- 합성곱 신경망 U-Net LeNet 알렉스넷 딥드림
- 신경장 신경 방사장 물리정보 신경망
- 트랜스포머 비전
- 맘바
- 스파이킹 신경망
- 멤트렌지스터
- 전기화학 RAM
- 다층 퍼셉트론

- LSTM
- GRU

- 제한된

- U-Net
- LeNet
- 알렉스넷
- 딥드림

- 신경 방사장
- 물리정보 신경망

- 비전

- Q 러닝
- SARSA
- 시간차 학습

- 액티브 러닝
- 크라우드소싱
- 휴먼인더루프
- RLHF

- 결정계수
- 혼동 행렬
- 러닝 커브
- 수신자 조작 특성

- 커널 메소드
- 편향-분산 트레이드오프
- 계산학습이론
- 경험적 위험 최소화
- PAC 러닝
- 통계적 학습이론
- VC 이론

- NeurIPS
- ICML
- ICLR
- ML
- JMLR

- 기계 학습 알고리즘 목록
- 기계 탈학습
- 지식 증류
- 유사도 학습
- 대조 학습

- v
- t
- e

- 인공 일반 지능
- 지능형 에이전트
- 재귀적 자기 개선
- 컴퓨터 비전
- 지식 표현
- 자연어 처리
- 로봇공학
- AI 안전

- 기계 학습
- 기호주의
- 딥 러닝
- 베이즈 네트워크
- 진화 알고리즘
- 하이브리드 인텔리전트 시스템
- 인공지능 시스템 통합

- 딥페이크
- 생성형 인공지능 예술 오디오
- 정부의 인공 지능
- 보건분야의 인공지능
- 산업 인공지능
- 기계 번역

- 예술
- 오디오

- 인공 의식
- 중국어 방
- 친절한 AI
- AI 정렬/AI에 의한 탈취
- 윤리
- 실존적 위험
- 튜링 테스트
- 불쾌한 골짜기

- 연표
- 진행상황
- AI 겨울
- AI 붐

- 용어

- v
- t
- e

**기계 학습**(機械學習) 또는 **머신 러닝**([영어](https://ko.wikipedia.org/wiki/%EC%98%81%EC%96%B4): machine learning, **ML**)은 경험을 통해 자동으로 개선하는 컴퓨터 [알고리즘](https://ko.wikipedia.org/wiki/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)의 연구이다. 방대한 [데이터](https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0)를 분석해 '미래를 예측하는 기술'이자 [인공지능](https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5)의 한 분야로 간주된다. 기계 학습은 복잡한 패턴에 대한 학습을 통해 상황에 대한 예측과 의사 결정을 돕는다. [컴퓨터](https://ko.wikipedia.org/wiki/%EC%BB%B4%ED%93%A8%ED%84%B0)가 학습할 수 있도록 하는 [알고리즘](https://ko.wikipedia.org/wiki/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)과 기술을 개발하는 분야이다. 가령, 기계 학습을 통해서 수신한 [이메일](https://ko.wikipedia.org/wiki/%EC%9D%B4%EB%A9%94%EC%9D%BC)이 [스팸](https://ko.wikipedia.org/wiki/%EC%8A%A4%ED%8C%B8)인지 아닌지를 구분할 수 있도록 훈련할 수 있다.

기계 학습의 핵심은 표현(representation)과 일반화(generalization)에 있다. 표현이란 데이터의 평가이며, 일반화란 아직 알 수 없는 데이터에 대한 처리이다. 이는 [전산 학습 이론](https://ko.wikipedia.org/w/index.php?title=%EC%A0%84%EC%82%B0_%ED%95%99%EC%8A%B5_%EC%9D%B4%EB%A1%A0&action=edit&redlink=1) 분야이기도 하다. 다양한 기계 학습의 응용이 존재한다. [문자 인식](https://ko.wikipedia.org/wiki/%EA%B4%91%ED%95%99_%EB%AC%B8%EC%9E%90_%EC%9D%B8%EC%8B%9D)은 이를 이용한 가장 잘 알려진 사례이다.

### 정의

1959년, [아서 사무엘](https://ko.wikipedia.org/w/index.php?title=%EC%95%84%EC%84%9C_%EC%82%AC%EB%AC%B4%EC%97%98&action=edit&redlink=1)은 기계 학습을 "기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야"라고 정의하였다.

### 일반화

기계 학습에서의 일반화는 [훈련](https://ko.wikipedia.org/wiki/%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5) 이후 새롭게 들어온 데이터를 정확히 처리할 수 있는 능력을 말한다.

### 기계 학습과 데이터 마이닝

기계 학습과 데이터 마이닝은 종종 같은 방법을 사용하며 상당히 중첩된다. 다만 다음에 따라 대략적으로 구분된다.

- 기계 학습은 훈련 데이터를 통해 학습된 알려진 속성을 기반으로 예측에 초점을 두고 있다.
- 데이터 마이닝은 데이터의 미처 몰랐던 속성을 발견하는 것에 집중한다. 이는 데이터베이스의 지식 발견 부분의 분석 절차에 해당한다.

### 이론

[이론 전산학](https://ko.wikipedia.org/wiki/%EC%9D%B4%EB%A1%A0_%EC%A0%84%EC%82%B0%ED%95%99)의 한 갈래이다. 훈련 데이터는 유한한데, 결과는 불확실하다. 이는 학습 이론을 통해 알고리즘의 결과를 장담할 수 없기 때문이다. 또한 다른 용어를 사용함에도 불구하고 [통계적 추론](https://ko.wikipedia.org/wiki/%ED%86%B5%EA%B3%84%EC%A0%81_%EC%B6%94%EB%A1%A0)과도 많은 유사점이 있다.

### 알고리즘 유형

- 지도 학습
- 자율 학습 (기계 학습)
- 준 지도 학습
- 강화 학습
- 심화 학습

### 접근 방법별 알고리즘

#### 결정 트리 학습법

#### 연관 규칙 학습법

#### 인공신경망

인공신경망(artificial neural network, ANN)은 기계학습과 [인지과학](https://ko.wikipedia.org/wiki/%EC%9D%B8%EC%A7%80%EA%B3%BC%ED%95%99)에서 생물학의 신경망에서 영감을 얻은 통계학적 학습 [알고리즘](https://ko.wikipedia.org/wiki/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)으로 [시냅스](https://ko.wikipedia.org/wiki/%EC%8B%9C%EB%83%85%EC%8A%A4)의 결합으로 [네트워크](https://ko.wikipedia.org/wiki/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC)를 형성한 [인공 뉴런](https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EB%89%B4%EB%9F%B0)(노드)이 학습을 통해 [시냅스](https://ko.wikipedia.org/wiki/%EC%8B%9C%EB%83%85%EC%8A%A4)의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 가리킨다. 인공신경망에는 교사 신호(정답)의 입력에 의해서 문제에 최적화되어 가는 [교사 학습](https://ko.wikipedia.org/wiki/%EA%B5%90%EC%82%AC_%ED%95%99%EC%8A%B5)과 교사 신호를 필요로 하지 않는 [비교사 학습](https://ko.wikipedia.org/wiki/%EB%B9%84%EA%B5%90%EC%82%AC_%ED%95%99%EC%8A%B5)이 있다. 명확한 해답이 있는 경우에는 교사 학습이, [데이터 클러스터링](https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81)에는 비교사 학습이 이용된다. 다른 기계학습과 같이 신경망은 일반적으로 규칙기반 프로그래밍으로 풀기 어려운 [컴퓨터 비전](https://ko.wikipedia.org/wiki/%EC%BB%B4%ED%93%A8%ED%84%B0_%EB%B9%84%EC%A0%84) 또는 [음성 인식](https://ko.wikipedia.org/wiki/%EC%9D%8C%EC%84%B1_%EC%9D%B8%EC%8B%9D)과 같은 다양한 범위의 문제를 푸는데 이용된다.

#### 유전 계획법

#### 귀납 논리 계획법

#### 서포트 벡터 머신

#### 클러스터링

#### 베이즈 네트워크

#### 강화 학습법

#### 표현 학습법

#### 동일성 계측 학습법

### 주제별 알고리즘

- 선수 지식 베이즈 이론
- 모형화 인공 신경망 결정 트리 학습법 유전 알고리즘 (Genetic Algorithm) 유전자 프로그래밍 가우스 과정 회귀 선형 분별 분석 K-최근접 이웃 알고리즘 퍼셉트론 방사 기저 함수 네트워크 서포트 벡터 머신 (support vector machine)
- 모수 추정 알고리즘 동적 프로그래밍 기댓값 최대화 알고리즘
- 생성 모형을 이용한 확률 분포 함수의 모형화 베이즈 네트워크와 마르코프 임의장을 포함한 그래프 모형
- 근사 추론 기법 몬테 카를로 방법 아다부스트

- 베이즈 이론

- 인공 신경망
- 결정 트리 학습법
- 유전 알고리즘 (Genetic Algorithm)
- 유전자 프로그래밍
- 가우스 과정 회귀
- 선형 분별 분석
- K-최근접 이웃 알고리즘
- 퍼셉트론
- 방사 기저 함수 네트워크
- 서포트 벡터 머신 (support vector machine)

- 동적 프로그래밍
- 기댓값 최대화 알고리즘

- 베이즈 네트워크와 마르코프 임의장을 포함한 그래프 모형

- 몬테 카를로 방법
- 아다부스트